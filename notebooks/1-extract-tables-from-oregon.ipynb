{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd652a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pyparsing as pp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccb0d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tables(page_start,page_end,pages):\n",
    "    final_table = []\n",
    "    for page_num in range(page_start-1,page_end):\n",
    "        header = 'Workplace Address County Investigation start date Most recent onset Total cases '\n",
    "        raw = pages[page_num].text.replace('\\n','')\n",
    "        #outbreaks = raw[(raw.find(header) + len(header)):]\n",
    "        outbreaks = raw.split(header)\n",
    "        if len(outbreaks) >= 1:\n",
    "            #print(page_num)\n",
    "            for outbreak in outbreaks:\n",
    "                if 'Table 5.' in outbreak:\n",
    "                    outbreak = outbreak[:outbreak.find('Table 5.')]\n",
    "                table = pp.Group(pp.OneOrMore(pp.Word(pp.alphas) + pp.pyparsing_common.iso8601_date + pp.pyparsing_common.iso8601_date + pp.pyparsing_common.integer))\n",
    "                workplace_start = 0\n",
    "                for result, start, end in table.scanString(outbreak):\n",
    "                    for raw_row in result:\n",
    "                        find = \" \".join([str(r) for r in raw_row.asList()])\n",
    "                        workplace_end = outbreak.find(find)\n",
    "                        workplace = outbreak[workplace_start:workplace_end]\n",
    "                        row = [workplace]\n",
    "                        row.extend(raw_row)\n",
    "                        final_table.append(row)\n",
    "                        workplace_start = outbreak.find(find) + len(find)\n",
    "        else:\n",
    "            print(page_num)\n",
    "            print(outbreaks)\n",
    "    return final_table\n",
    "\n",
    "\n",
    "def last_updated(page):\n",
    "    content = page.text\n",
    "    keyphrase = 'Data for this week are up to date as of'\n",
    "    phrase_start = content.find(keyphrase) + len(keyphrase)\n",
    "    \n",
    "    first_digit = re.search(r\"\\d\", content[phrase_start:])\n",
    "    assert(first_digit)\n",
    "    first_period = content[(phrase_start + first_digit.start()):].find(\".\")\n",
    "    first_space = content[(phrase_start + first_digit.start()):].find(\" \")\n",
    "    phrase_end = phrase_start + (first_digit.start() + min(first_period,first_space))\n",
    "    phrase = content[phrase_start:phrase_end].strip()\n",
    "    print(phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6afa5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sunday, May 16\n",
      ">>>>>>  2021-5-19 total pages in doc: 120, start page: 44, end page: 55\n",
      "0\n",
      "Sunday, \n",
      "October 10\n",
      ">>>>>>  2021-10-27 total pages in doc: 157, start page: 60, end page: 70\n",
      "0\n",
      "Sunday, August 15\n",
      ">>>>>>  2021-08-18 total pages in doc: 72, start page: 51, end page: 61\n",
      "0\n",
      "Sunday, April 18\n",
      ">>>>>>  2021-4-21 total pages in doc: 95, start page: 42, end page: 51\n",
      "0\n",
      "Sunday, June 27\n",
      ">>>>>>  2021-6-30 total pages in doc: 128, start page: 46, end page: 53\n",
      "0\n",
      "Sunday, April 11\n",
      ">>>>>>  2021-4-14 total pages in doc: 90, start page: 41, end page: 50\n",
      "0\n",
      "Sunday, August 29\n",
      ">>>>>>  2021-09-01 total pages in doc: 82, start page: 55, end page: 68\n",
      "0\n",
      "Sunday, May 9\n",
      ">>>>>>  2021-5-12 total pages in doc: 115, start page: 44, end page: 54\n",
      "0\n",
      "Sunday, September 12\n",
      ">>>>>>  2021-09-15 total pages in doc: 109, start page: 59, end page: 75\n",
      "0\n",
      "Sunday, October 10\n",
      ">>>>>>  2021-10-13 total pages in doc: 177, start page: 65, end page: 79\n",
      "0\n",
      "Sunday, May 23\n",
      ">>>>>>  2021-05-26 total pages in doc: 124, start page: 44, end page: 55\n",
      "0\n",
      "Sunday, July 25\n",
      ">>>>>>  2021-7-28 total pages in doc: 59, start page: 48, end page: 53\n",
      "0\n",
      "Sunday, May 2\n",
      ">>>>>>  2021-5-5 total pages in doc: 109, start page: 43, end page: 54\n",
      "0\n",
      "Sunday, June 13\n",
      ">>>>>>  2021-6-16 total pages in doc: 129, start page: 45, end page: 55\n",
      "0\n",
      "Sunday, June 20\n",
      ">>>>>>  2021-6-23 total pages in doc: 128, start page: 45, end page: 53\n",
      "0\n",
      "Sunday, April 4\n",
      ">>>>>>  2021-4-7 total pages in doc: 85, start page: 41, end page: 49\n",
      "0\n",
      "Sunday, \n",
      "October 17\n",
      ">>>>>>  2021-10-20 total pages in doc: 186, start page: 68, end page: 82\n",
      "0\n",
      "Sunday, June 6\n",
      ">>>>>>  2021-6-9 total pages in doc: 130, start page: 45, end page: 56\n",
      "0\n",
      "Sunday, April 25\n",
      ">>>>>>  2021-4-28 total pages in doc: 101, start page: 43, end page: 53\n",
      "0\n",
      "Sunday, \n",
      "November 28\n",
      ">>>>>>  2021-12-01 total pages in doc: 177, start page: 82, end page: 91\n",
      "0\n",
      "Sunday, September 26\n",
      ">>>>>>  2021-09-29 total pages in doc: 152, start page: 63, end page: 79\n",
      "0\n",
      "Sunday, March 28\n",
      ">>>>>>  2021-3-31 total pages in doc: 83, start page: 41, end page: 49\n",
      "0\n",
      "Sunday, October 3\n",
      ">>>>>>  2021-10-06 total pages in doc: 171, start page: 63, end page: 79\n",
      "1\n",
      "Sunday, \n",
      "November 7\n",
      ">>>>>>  2021-11-10 total pages in doc: 156, start page: 61, end page: 70\n",
      "0\n",
      "Sunday, August 8\n",
      ">>>>>>  2021-08-11 total pages in doc: 67, start page: 50, end page: 58\n",
      "0\n",
      "Sunday, September 19\n",
      ">>>>>>  2021-09-22 total pages in doc: 125, start page: 61, end page: 76\n",
      "0\n",
      "Sunday, October 31\n",
      ">>>>>>  2021-11-03 total pages in doc: 157, start page: 60, end page: 70\n",
      "0\n",
      "Sunday, \n",
      "November 14\n",
      ">>>>>>  2021-11-17 total pages in doc: 193, start page: 81, end page: 91\n",
      "0\n",
      "Sunday, July 18\n",
      ">>>>>>  2021-07-21 total pages in doc: 60, start page: 47, end page: 52\n",
      "0\n",
      "Sunday, September 5\n",
      ">>>>>>  2021-09-09 total pages in doc: 96, start page: 58, end page: 72\n",
      "0\n",
      "Sunday, July 11\n",
      ">>>>>>  2021-07-14 total pages in doc: 127, start page: 46, end page: 52\n",
      "0\n",
      "Sunday, March 21\n",
      ">>>>>>  2021-3-24 total pages in doc: 82, start page: 40, end page: 49\n",
      "0\n",
      "Sunday, \n",
      "November 21\n",
      ">>>>>>  2021-11-24 total pages in doc: 187, start page: 81, end page: 90\n",
      "0\n",
      "Sunday, August 1\n",
      ">>>>>>  2021-08-04 total pages in doc: 63, start page: 48, end page: 55\n",
      "0\n",
      "Sunday, March 14\n",
      ">>>>>>  2021-3-17 total pages in doc: 81, start page: 39, end page: 49\n",
      "0\n",
      "Sunday, August 22\n",
      ">>>>>>  2021-08-25 total pages in doc: 78, start page: 53, end page: 65\n"
     ]
    }
   ],
   "source": [
    "folder = '../data/oregon-xml/'\n",
    "full_data = pd.DataFrame()\n",
    "for fn in [f for f in os.listdir(folder) if f.endswith('.xml')]:\n",
    "    with open(f\"{folder}{fn}\", 'r') as xmlfile:\n",
    "        contents = xmlfile.read()\n",
    "    soup = BeautifulSoup(contents)\n",
    "    pages = soup.find_all('div',class_=\"page\")\n",
    "    \n",
    "    first_page = pages[0]\n",
    "    grafs = first_page.find_all('p')\n",
    "\n",
    "    indice = [ind for ind, graf in enumerate(grafs) if graf.text.startswith('Table 3')][0]\n",
    "\n",
    "    start_page = int(grafs[indice].text.split('.')[-1].strip())\n",
    "    end_page = int(grafs[indice + 2].text.split('.')[-1].strip())\n",
    "    \n",
    "    intro_indice = [ind for ind, graf in enumerate(grafs) if 'Introduction' in graf.text][0]\n",
    "    intro_page = int(grafs[intro_indice].text.split('.')[-1].strip()) - 1\n",
    "    as_of = last_updated(pages[intro_page])\n",
    "    \n",
    "    report_date = fn[fn.find('2021'):fn.find('-FINAL.xml')]\n",
    "    print(\">>>>>> \",report_date, f\"total pages in doc: {len(pages)}, start page: {start_page}, end page: {end_page}\")\n",
    "    tt = scrape_tables(start_page,end_page,pages)\n",
    "    df = pd.DataFrame(tt,columns=['workplace_address','county','investigation_start_date','most_recent_onset','total_cases'])\n",
    "    df['report_date'] = report_date\n",
    "    df['last_updated'] = as_of\n",
    "    full_data = pd.concat([full_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91589438",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_report = full_data['report_date'].apply(pd.to_datetime).max().strftime('%Y-%m-%d')\n",
    "full_data.to_csv(f'../output/oha-data-{latest_report}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
